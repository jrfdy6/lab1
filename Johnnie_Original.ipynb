{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "source": "\"\"\"\n\nIn this case, imputing helps the classifier get close to the original score.\n\nCross Validation Link:\nhttp://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html#sphx-glr-auto-examples-model-selection-grid-search-digits-py\n  \n\"\"\"\n\n##############################\n# Module imports and dependencies\n##############################\n\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport os\nimport sklearn\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_boston\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.cluster import KMeans\n\n\n##############################\n# Import Dataframe and Explore\n##############################\n\n# We have an existing pickle.pickle, which is a dataframe of our cleaned SportsVU elements\n \n\n#dir = os.path.dirname(__file__) #dirname'\nos.chdir('C:\\\\Users\\\\Haykay\\\\Downloads\\\\')\nfilename = os.path.join(os.getcwd(), 'data','pickle.pickle')\n\npd.options.mode.chained_assignment = None\n\ndf= pd.read_pickle(filename)\ndf.columns\n\n\n#player id is the person who took the shot, as file has already been subset to only shot taking events.\ntestlist = ['PLAYER1_ID', 'PERSON3TYPE']\nbroketest = df[testlist]\n\noutcomes = df['PLAYER1_ID']\noutcomes = outcomes.astype('category')\n\n\n#need to identify tuples for our columns.\ndef gen_predictors(df):\n    colnames_pred = []\n    for i in df.columns:\n        if isinstance(i, tuple):\n            colnames_pred.append(i)\n    colnames_pred = colnames_pred[2:]\n            \n    len(colnames_pred)\n    \n    ####Imputing values for players in bench\n    predictors = df[colnames_pred]\n    type(predictors)\n    #eliminated -100 predictors until later step.\n        \n    return predictors\n    \npred_trans = gen_predictors(df)\npred_trans.ix[:,1].describe() #Identify xmax range, 100\npred_trans.is_copy\npred_trans.ix[:,899].describe() #identify ymax range, 50\npred_trans.is_copy\n #identify ymin, 0\n\n\n#==============================================================================\n# Transform predictors so that our \n#==============================================================================\n\n## How to only iterate over the tuples of a list???\n\n#Fix the -100s..... for x coordinates.\n#get all column names with 'xloc'\ndef halftime_xlist(predict_trans):\n    holdingcol = []\n    for (xvar, obs, name) in predict_trans.columns.values:\n        if xvar == 'x_loc':\n            tupler = (xvar, obs, name)\n            holdingcol.append(tupler)\n    return holdingcol\n    \n#Makes all left values inverted. Could probably combine these into one column with and if then statemetn.\ndef halftime_ylist(predictors):\n    holdingcol = []\n    for (xvar, obs, name) in predictors.columns.values:\n        if xvar == 'y_loc':\n            tupler = (xvar, obs, name)\n            holdingcol.append(tupler)\n    return holdingcol\n    \n\n#only works if all numpy operations are vectorized...don't have to specify observation number.\n#Can simply say, if column a, then column b does this, for all observations within each column.\n\ndef halftime_transform(prediction_df):\n    predict_trans = prediction_df\n    column_listx = halftime_xlist(predict_trans)\n    column_listy = halftime_ylist(predict_trans)\n    \n    predict_trans['CourtCount'] = 0 \n    #Counter of how many x coordinates are on the left side of the court vs the right.\n\n    for i in column_listx:\n        predict_trans['CourtCount'] = np.where(predict_trans[i] >= 48, predict_trans['CourtCount']+1, predict_trans['CourtCount'])\n        predict_trans['CourtCount'] = np.where(predict_trans[i] <  48, predict_trans['CourtCount']-1, predict_trans['CourtCount'])\n        #Double check NA handling.\n    \n    \n    for i in column_listx:\n        predict_trans[i] = np.where(predict_trans['CourtCount'] < -5, 95-predict_trans[i], predict_trans[i])\n\n    for i in column_listy:\n        predict_trans[i] = np.where(predict_trans['CourtCount'] < -5, 50-predict_trans[i], predict_trans[i])\n\n        \n    predict_trans.fillna(-200, inplace = True) #We can finally fill in our NA's once we've fixed our shit.\n    return predict_trans\n\n\npredictors = halftime_transform(pred_trans)\npredictors.CourtCount.describe()\nlen(predictors2.columns)\npredictors2 = predictors.ix[:,0:900]\npredictors2.is_copy\ntype(predictors)\ndf[('x_loc', 29, 'Boris Diaw')] # just test code to ensure that this shitzle works.\n\n\n    \n#==============================================================================\n# RandomForest (Classifier Variant) Model Fitting parameters\n#==============================================================================\n\nestimator = Pipeline([(\"forest\", RandomForestClassifier(random_state=0, n_estimators=100))])\nestimator.fit(predictors2, outcomes)\n\npredicted = estimator.predict(predictors2) \nprediction_scores  = accuracy_score(outcomes, predicted) #This code will change, fi we cross validate\n\n#test_predicted = estimator.predict(test_predictors) \n#prediction_scores  = accuracy_score(test_outcomes, test_predicted)\n\nprint(prediction_scores)\n\nwith open(os.path.join(os.getcwd(), 'data','RF.pickle'), 'wb') as pickle_file:\n    pickle.dump(estimator, pickle_file)\n\n\n\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "#df.dtypes\nnew_df = pd.DataFrame()\nnew_df['PERIOD'] = df['PERIOD']\nnew_df['PLAYER1_ID'] = df['PLAYER1_ID']\nnew_df['PLAYER2_ID'] = df['PLAYER2_ID']\nnew_df['PLAYER3_ID'] = df['PLAYER3_ID']\nval = new_df.values\nk = 8\nkm = KMeans(n_clusters=1)\nkm.fit(val)\nlabels = km.labels_\ncentroids = kmeans.cluster_centers_\nfor i in range(k):\n    ds = val[np.where(labels==i)]\n    plt.plot(val[:,0],ds[:,1],'o')\n    lines = plt.plot(centroids[i,0],centroids[i,1],'kx')\n    plt.setp(lines,ms=15.0)\n    plt.setp(lines,mew=2.0)\n    pass\nplt.show()", "outputs": [{"ename": "NameError", "evalue": "name 'pd' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-3-8089e286919d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#df.dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERIOD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERIOD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER1_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER1_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER2_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER2_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"], "output_type": "error"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.1", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}